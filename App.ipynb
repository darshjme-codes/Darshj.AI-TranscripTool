"""
ğŸš€ Darshj.AI - Ultimate Transcription Dashboard
================================================
Transcribe like a PRO with AI-powered magic! âœ¨
"""

# %% [markdown]
# # ğŸ¯ Darshj.AI - Ultimate Transcription Dashboard 
# ### ğŸ™ï¸ *Transcribe Anything, Anywhere, Anytime!*
# 
# <div align="center">
#     <img src="https://img.shields.io/badge/Darshj.AI-Transcription_Magic-FF6B6B?style=for-the-badge&logo=python&logoColor=white" />
#     <img src="https://img.shields.io/badge/Powered_by-Whisper_AI-4ECDC4?style=for-the-badge&logo=openai&logoColor=white" />
#     <img src="https://img.shields.io/badge/Built_with-â¤ï¸-FFE66D?style=for-the-badge" />
# </div>
#
# ---
# 
# ## ğŸ¬ What's This Magic?
# Transform your audio/video files into text with AI superpowers! Built with love by **Darshj.AI** ğŸš€

# %% [markdown]
# ## ğŸ“¦ Step 1: Auto-Magic Installation âœ¨

# %%
import subprocess
import sys
import os
import platform
from IPython.display import HTML, display
import time

def animated_install():
    """Install packages with fun animations"""
    
    # Display branded header
    display(HTML("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 30px; border-radius: 15px; text-align: center; color: white;">
        <h1 style="margin: 0; font-size: 3em;">ğŸš€ Darshj.AI</h1>
        <p style="font-size: 1.2em; margin-top: 10px;">Initializing Transcription Magic...</p>
        <div id="loading" style="margin-top: 20px;">
            <style>
                @keyframes pulse {
                    0% { transform: scale(1); }
                    50% { transform: scale(1.1); }
                    100% { transform: scale(1); }
                }
                .emoji-loader {
                    font-size: 2em;
                    animation: pulse 1s infinite;
                    display: inline-block;
                    margin: 0 5px;
                }
            </style>
            <span class="emoji-loader">ğŸ¯</span>
            <span class="emoji-loader" style="animation-delay: 0.2s;">ğŸ™ï¸</span>
            <span class="emoji-loader" style="animation-delay: 0.4s;">âœ¨</span>
            <span class="emoji-loader" style="animation-delay: 0.6s;">ğŸš€</span>
        </div>
    </div>
    """))
    
    packages = [
        ('gradio>=4.0.0', 'ğŸ¨'),
        ('openai-whisper', 'ğŸ¤–'),
        ('ffmpeg-python', 'ğŸ¬'),
        ('numpy', 'ğŸ”¢'),
        ('torch', 'ğŸ”¥'),
        ('torchaudio', 'ğŸµ'),
        ('pandas', 'ğŸ“Š'),
        ('plotly', 'ğŸ“ˆ'),
        ('python-dotenv', 'ğŸ”'),
        ('humanize', 'ğŸ‘¤'),
        ('tqdm', 'ğŸ“Š'),
        ('requests', 'ğŸŒ'),
        ('Pillow', 'ğŸ–¼ï¸'),
        ('pydub', 'ğŸ¼'),
        ('psutil', 'ğŸ’»')
    ]
    
    print("\nğŸ¯ Darshj.AI Package Installer Starting...\n")
    print("="*50)
    
    for package, emoji in packages:
        print(f"\n{emoji} Installing {package}...")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])
            print(f"   âœ… {package} installed successfully!")
        except:
            print(f"   âš ï¸ {package} might already be installed")
    
    # Install FFmpeg
    print("\nğŸ¬ Setting up FFmpeg...")
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        print("   âœ… FFmpeg is ready to rock!")
    except:
        print("   ğŸ“¦ Installing FFmpeg...")
        if platform.system() == "Linux":
            try:
                subprocess.run(['apt-get', 'update'], check=True, capture_output=True)
                subprocess.run(['apt-get', 'install', '-y', 'ffmpeg'], check=True, capture_output=True)
                print("   âœ… FFmpeg installed!")
            except:
                print("   âš ï¸ Please install FFmpeg manually")
        else:
            print("   â„¹ï¸ Please install FFmpeg manually for your OS")
    
    print("\n" + "="*50)
    print("ğŸ‰ All systems GO! Let's transcribe some magic! ğŸ‰\n")
    
    # Display success animation
    display(HTML("""
    <div style="text-align: center; padding: 20px;">
        <div style="font-size: 4em; animation: pulse 1s infinite;">âœ¨</div>
        <h2 style="color: #667eea;">Darshj.AI Ready!</h2>
    </div>
    """))

# Run the animated installer
animated_install()

# %% [markdown]
# ## ğŸ¨ Step 2: Import the Magic Libraries

# %%
import gradio as gr
import whisper
import ffmpeg
import json
import tempfile
import shutil
from datetime import datetime
from typing import Optional, Dict, List, Tuple, Any
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import numpy as np
import torch
import warnings
import random
import asyncio
from dataclasses import dataclass, field
from collections import defaultdict
import threading
import queue
import humanize
import base64
from PIL import Image, ImageDraw, ImageFont
import io
import requests
import psutil
import gc

warnings.filterwarnings('ignore')

print("ğŸ¯ Darshj.AI: All libraries loaded successfully!")
print(f"ğŸ”¥ Running on: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
print(f"ğŸ’» System: {platform.system()} {platform.machine()}")

# %% [markdown]
# ## ğŸ§  Step 3: Core Brain Components

# %%
# Fun loading messages for user entertainment
LOADING_MESSAGES = [
    "ğŸ¯ Warming up the AI engines...",
    "ğŸš€ Preparing transcription rockets...",
    "âœ¨ Sprinkling some AI magic dust...",
    "ğŸ™ï¸ Tuning the digital microphones...",
    "ğŸ¤– Waking up the Whisper wizards...",
    "ğŸ’« Aligning the neural networks...",
    "ğŸ¬ Setting up the media processors...",
    "ğŸ”® Consulting the transcription oracle...",
    "âš¡ Charging the AI batteries...",
    "ğŸª Starting the transcription show..."
]

# Brand colors for Darshj.AI
BRAND_COLORS = {
    'primary': '#667eea',
    'secondary': '#764ba2',
    'accent': '#f093fb',
    'success': '#4ECDC4',
    'warning': '#FFE66D',
    'danger': '#FF6B6B'
}

@dataclass
class DarshjStats:
    """Statistics tracker for Darshj.AI"""
    total_files: int = 0
    total_duration: float = 0.0
    total_words: int = 0
    total_characters: int = 0
    languages_detected: Dict[str, int] = field(default_factory=dict)
    file_formats: Dict[str, int] = field(default_factory=dict)
    processing_speeds: List[float] = field(default_factory=list)
    confidence_scores: List[float] = field(default_factory=list)
    daily_usage: Dict[str, int] = field(default_factory=dict)
    
    def add_transcription(self, duration: float, text: str, language: str, 
                         format: str, speed: float, confidence: float):
        self.total_files += 1
        self.total_duration += duration
        self.total_words += len(text.split())
        self.total_characters += len(text)
        self.languages_detected[language] = self.languages_detected.get(language, 0) + 1
        self.file_formats[format] = self.file_formats.get(format, 0) + 1
        self.processing_speeds.append(speed)
        self.confidence_scores.append(confidence)
        
        today = datetime.now().strftime("%Y-%m-%d")
        self.daily_usage[today] = self.daily_usage.get(today, 0) + 1
    
    def get_achievement_level(self) -> Tuple[str, str]:
        """Get user achievement level based on usage"""
        if self.total_files >= 100:
            return "ğŸ†", "Transcription Master"
        elif self.total_files >= 50:
            return "ğŸ¥‡", "Transcription Expert"
        elif self.total_files >= 20:
            return "ğŸ¥ˆ", "Transcription Pro"
        elif self.total_files >= 10:
            return "ğŸ¥‰", "Transcription Enthusiast"
        elif self.total_files >= 5:
            return "â­", "Rising Star"
        else:
            return "ğŸŒŸ", "Beginner"

@dataclass
class TranscriptionMemory:
    """Memory system for Darshj.AI"""
    transcriptions: List[Dict[str, Any]] = field(default_factory=list)
    max_memory: int = 50
    
    def add(self, text: str, metadata: Dict):
        entry = {
            'text': text,
            'metadata': metadata,
            'timestamp': datetime.now().isoformat(),
            'id': f"darshj_{len(self.transcriptions) + 1}"
        }
        self.transcriptions.append(entry)
        if len(self.transcriptions) > self.max_memory:
            self.transcriptions.pop(0)
        return entry['id']
    
    def search(self, query: str) -> List[Dict]:
        """Search through transcription memory"""
        results = []
        query_lower = query.lower()
        for trans in self.transcriptions:
            if query_lower in trans['text'].lower():
                results.append(trans)
        return results
    
    def get_recent(self, n: int = 5) -> List[Dict]:
        """Get recent transcriptions"""
        return self.transcriptions[-n:] if self.transcriptions else []

# %% [markdown]
# ## ğŸ¤ Step 4: The Whisper Wizard

# %%
class DarshjWhisperWizard:
    """The magical Whisper transcription engine for Darshj.AI"""
    
    def __init__(self, model_size: str = "base"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"\nğŸ§™â€â™‚ï¸ Darshj.AI Whisper Wizard initializing...")
        print(f"   ğŸ“ Device: {self.device}")
        print(f"   ğŸ“ Model: {model_size}")
        
        # Load model with progress animation
        print(f"   â³ Loading Whisper {model_size} model...")
        self.model = whisper.load_model(model_size, device=self.device)
        print(f"   âœ… Whisper Wizard ready for magic!\n")
        
        self.supported_formats = ['.mp3', '.wav', '.mp4', '.avi', '.mov', '.flac', '.m4a', '.webm', '.ogg']
    
    def extract_audio_with_style(self, input_path: str, progress_callback=None) -> str:
        """Extract audio from video with progress updates"""
        if progress_callback:
            progress_callback("ğŸ¬ Extracting audio track...")
        
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_audio:
            try:
                stream = ffmpeg.input(input_path)
                stream = ffmpeg.output(stream, tmp_audio.name, 
                                      acodec='pcm_s16le', 
                                      ar='16000',
                                      ac=1)  # Mono for faster processing
                ffmpeg.run(stream, overwrite_output=True, quiet=True)
                
                if progress_callback:
                    progress_callback("âœ… Audio extracted successfully!")
                return tmp_audio.name
            except Exception as e:
                if progress_callback:
                    progress_callback(f"âŒ Audio extraction failed: {e}")
                raise
    
    def transcribe_with_magic(self, file_path: str, language: Optional[str] = None,
                            task: str = "transcribe", progress_callback=None) -> Dict:
        """Transcribe with Darshj.AI magic"""
        start_time = time.time()
        
        # Fun progress updates
        if progress_callback:
            progress_callback(random.choice(LOADING_MESSAGES))
        
        # Handle video files
        file_ext = Path(file_path).suffix.lower()
        audio_path = file_path
        
        if file_ext in ['.mp4', '.avi', '.mov', '.webm']:
            audio_path = self.extract_audio_with_style(file_path, progress_callback)
        
        try:
            if progress_callback:
                progress_callback("ğŸ¤– AI is listening to your file...")
            
            # Transcribe with Whisper
            result = self.model.transcribe(
                audio_path,
                language=language,
                task=task,
                verbose=False,
                fp16=self.device == "cuda"
            )
            
            if progress_callback:
                progress_callback("ğŸ“ Converting speech to text...")
            
            # Calculate metrics
            duration = result.get('segments', [{}])[-1].get('end', 0) if result.get('segments') else 0
            process_time = time.time() - start_time
            speed_ratio = duration / process_time if process_time > 0 else 0
            word_count = len(result['text'].split())
            
            # Extract detailed segments
            segments = []
            total_confidence = 0
            for seg in result.get('segments', []):
                confidence = np.exp(seg.get('avg_logprob', -1))
                segments.append({
                    'start': seg['start'],
                    'end': seg['end'],
                    'text': seg['text'],
                    'confidence': confidence
                })
                total_confidence += confidence
            
            avg_confidence = total_confidence / len(segments) if segments else 0.5
            
            # Clean up temp file
            if audio_path != file_path:
                os.unlink(audio_path)
            
            if progress_callback:
                progress_callback(f"âœ¨ Transcription complete! ({word_count} words)")
            
            return {
                'success': True,
                'text': result['text'],
                'language': result.get('language', 'unknown'),
                'segments': segments,
                'duration': duration,
                'word_count': word_count,
                'process_time': process_time,
                'speed_ratio': speed_ratio,
                'confidence': avg_confidence,
                'format': file_ext
            }
            
        except Exception as e:
            if audio_path != file_path and os.path.exists(audio_path):
                os.unlink(audio_path)
            return {'success': False, 'error': str(e)}

# %% [markdown]
# ## ğŸ“Š Step 5: Analytics & Visualization Engine

# %%
class DarshjAnalytics:
    """Analytics engine for beautiful visualizations"""
    
    def __init__(self, stats: DarshjStats):
        self.stats = stats
    
    def create_fun_stats_card(self) -> str:
        """Create an animated stats card"""
        if self.stats.total_files == 0:
            return """
            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        padding: 30px; border-radius: 20px; color: white; text-align: center;'>
                <h2>ğŸ¯ Welcome to Darshj.AI!</h2>
                <p style='font-size: 1.2em;'>Upload your first file to start the magic! âœ¨</p>
                <div style='font-size: 3em; margin: 20px;'>ğŸš€</div>
            </div>
            """
        
        emoji, level = self.stats.get_achievement_level()
        avg_speed = np.mean(self.stats.processing_speeds) if self.stats.processing_speeds else 0
        avg_confidence = np.mean(self.stats.confidence_scores) if self.stats.confidence_scores else 0
        
        return f"""
        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 25px; border-radius: 20px; color: white; position: relative;'>
            
            <div style='position: absolute; top: 20px; right: 20px; font-size: 2.5em;'>{emoji}</div>
            
            <h2 style='margin-top: 0;'>ğŸ¯ Darshj.AI Stats Dashboard</h2>
            <p style='opacity: 0.9; margin-bottom: 20px;'>Level: {level}</p>
            
            <div style='display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px;'>
                <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;'>
                    <div style='font-size: 2em; font-weight: bold;'>{self.stats.total_files}</div>
                    <div style='opacity: 0.8;'>Files Transcribed</div>
                </div>
                <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;'>
                    <div style='font-size: 2em; font-weight: bold;'>{self.stats.total_words:,}</div>
                    <div style='opacity: 0.8;'>Words Processed</div>
                </div>
                <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;'>
                    <div style='font-size: 2em; font-weight: bold;'>{humanize.naturaldelta(self.stats.total_duration)}</div>
                    <div style='opacity: 0.8;'>Audio Processed</div>
                </div>
            </div>
            
            <div style='margin-top: 20px; display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px;'>
                <div style='background: rgba(255,255,255,0.05); padding: 10px; border-radius: 8px;'>
                    <span style='opacity: 0.7;'>âš¡ Speed:</span> {avg_speed:.1f}x realtime
                </div>
                <div style='background: rgba(255,255,255,0.05); padding: 10px; border-radius: 8px;'>
                    <span style='opacity: 0.7;'>ğŸ¯ Accuracy:</span> {avg_confidence:.1%}
                </div>
            </div>
            
            <div style='margin-top: 15px; padding: 10px; background: rgba(255,255,255,0.1); 
                        border-radius: 10px; text-align: center;'>
                <span style='font-size: 1.5em;'>ğŸ†</span>
                <span style='margin-left: 10px;'>
                    {100 - self.stats.total_files if self.stats.total_files < 100 else 0} files to next level!
                </span>
            </div>
        </div>
        """
    
    def create_language_donut(self) -> go.Figure:
        """Create a fancy donut chart for languages"""
        if not self.stats.languages_detected:
            fig = go.Figure()
            fig.add_annotation(
                text="ğŸ¯ No data yet",
                showarrow=False,
                font=dict(size=20)
            )
            fig.update_layout(
                height=350,
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)'
            )
            return fig
        
        # Language emoji mapping
        lang_emojis = {
            'en': 'ğŸ‡¬ğŸ‡§', 'es': 'ğŸ‡ªğŸ‡¸', 'fr': 'ğŸ‡«ğŸ‡·', 'de': 'ğŸ‡©ğŸ‡ª',
            'it': 'ğŸ‡®ğŸ‡¹', 'pt': 'ğŸ‡µğŸ‡¹', 'ru': 'ğŸ‡·ğŸ‡º', 'ja': 'ğŸ‡¯ğŸ‡µ',
            'ko': 'ğŸ‡°ğŸ‡·', 'zh': 'ğŸ‡¨ğŸ‡³'
        }
        
        labels = [f"{lang_emojis.get(k, 'ğŸŒ')} {k.upper()}" 
                 for k in self.stats.languages_detected.keys()]
        
        fig = go.Figure(data=[
            go.Pie(
                labels=labels,
                values=list(self.stats.languages_detected.values()),
                hole=0.4,
                marker=dict(
                    colors=px.colors.sequential.Plasma,
                    line=dict(color='white', width=2)
                ),
                textfont=dict(size=14, color='white'),
                hovertemplate='<b>%{label}</b><br>Files: %{value}<br>%{percent}<extra></extra>'
            )
        ])
        
        fig.add_annotation(
            text="ğŸŒ",
            showarrow=False,
            font=dict(size=40)
        )
        
        fig.update_layout(
            title="<b>ğŸ—£ï¸ Language Distribution</b>",
            height=350,
            showlegend=True,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#667eea')
        )
        
        return fig
    
    def create_speed_chart(self) -> go.Figure:
        """Create an animated speed performance chart"""
        if not self.stats.processing_speeds:
            fig = go.Figure()
            fig.add_annotation(
                text="âš¡ No speed data yet",
                showarrow=False,
                font=dict(size=20)
            )
            fig.update_layout(
                height=350,
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)'
            )
            return fig
        
        x_data = list(range(1, len(self.stats.processing_speeds) + 1))
        
        fig = go.Figure()
        
        # Add speed line
        fig.add_trace(go.Scatter(
            x=x_data,
            y=self.stats.processing_speeds,
            mode='lines+markers',
            name='Speed',
            line=dict(color='#667eea', width=3),
            marker=dict(size=10, color='#764ba2'),
            fill='tozeroy',
            fillcolor='rgba(102, 126, 234, 0.2)',
            hovertemplate='File #%{x}<br>Speed: %{y:.1f}x<extra></extra>'
        ))
        
        # Add average line
        avg_speed = np.mean(self.stats.processing_speeds)
        fig.add_hline(
            y=avg_speed,
            line_dash="dash",
            line_color="#FF6B6B",
            annotation_text=f"Avg: {avg_speed:.1f}x"
        )
        
        fig.update_layout(
            title="<b>âš¡ Processing Speed (Realtime Multiple)</b>",
            xaxis_title="File Number",
            yaxis_title="Speed (x realtime)",
            height=350,
            hovermode='x unified',
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#667eea'),
            xaxis=dict(gridcolor='rgba(0,0,0,0.1)'),
            yaxis=dict(gridcolor='rgba(0,0,0,0.1)')
        )
        
        return fig
    
    def create_daily_heatmap(self) -> go.Figure:
        """Create a GitHub-style activity heatmap"""
        if not self.stats.daily_usage:
            fig = go.Figure()
            fig.add_annotation(
                text="ğŸ“… No daily data yet",
                showarrow=False,
                font=dict(size=20)
            )
            fig.update_layout(
                height=200,
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)'
            )
            return fig
        
        # Prepare data for heatmap
        dates = pd.date_range(
            end=datetime.now(),
            periods=30
        )
        
        values = [self.stats.daily_usage.get(d.strftime("%Y-%m-%d"), 0) for d in dates]
        
        fig = go.Figure(data=go.Heatmap(
            z=[values[i:i+7] for i in range(0, len(values), 7)],
            colorscale='Plasma',
            showscale=False,
            hovertemplate='Files: %{z}<extra></extra>'
        ))
        
        fig.update_layout(
            title="<b>ğŸ“… 30-Day Activity</b>",
            height=200,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#667eea'),
            xaxis=dict(showticklabels=False, showgrid=False),
            yaxis=dict(showticklabels=False, showgrid=False)
        )
        
        return fig

# %% [markdown]
# ## ğŸ¨ Step 6: The Magical Gradio Dashboard

# %%
class DarshjTranscriptionDashboard:
    """The main Darshj.AI dashboard application"""
    
    def __init__(self):
        print("\nğŸ¯ Initializing Darshj.AI Dashboard...")
        self.wizard = DarshjWhisperWizard(model_size="base")
        self.stats = DarshjStats()
        self.memory = TranscriptionMemory()
        self.analytics = DarshjAnalytics(self.stats)
        print("âœ¨ Darshj.AI Dashboard ready!\n")
    
    def process_file_with_magic(self, file, language, task, export_format):
        """Process file with Darshj.AI magic"""
        if file is None:
            return (
                "ğŸ¯ Please upload a file to start the magic!",
                "",
                self.analytics.create_fun_stats_card(),
                self.analytics.create_language_donut(),
                self.analytics.create_speed_chart(),
                None
            )
        
        # Progress tracking
        progress_messages = []
        def update_progress(msg):
            progress_messages.append(msg)
        
        # Transcribe with magic
        result = self.wizard.transcribe_with_magic(
            file.name,
            language=language if language != "Auto-detect" else None,
            task=task,
            progress_callback=update_progress
        )
        
        if not result['success']:
            return (
                f"âŒ Oops! Something went wrong: {result.get('error', 'Unknown error')}",
                "",
                self.analytics.create_fun_stats_card(),
                self.analytics.create_language_donut(),
                self.analytics.create_speed_chart(),
                None
            )
        
        # Update stats
        self.stats.add_transcription(
            duration=result['duration'],
            text=result['text'],
            language=result['language'],
            format=result['format'],
            speed=result['speed_ratio'],
            confidence=result['confidence']
        )
        
        # Add to memory
        trans_id = self.memory.add(
            result['text'],
            {
                'language': result['language'],
                'duration': result['duration'],
                'word_count': result['word_count'],
                'confidence': result['confidence']
            }
        )
        
        # Format output with style
        output_text = f"""
ğŸ¯ **Darshj.AI Transcription Complete!**

ğŸ“Š **Stats:**
â€¢ Language: {result['language'].upper()} 
â€¢ Duration: {humanize.naturaldelta(result['duration'])}
â€¢ Words: {result['word_count']:,}
â€¢ Speed: {result['speed_ratio']:.1f}x realtime
â€¢ Confidence: {result['confidence']:.1%}
â€¢ ID: {trans_id}

ğŸ“ **Transcription:**
{result['text']}
        """
        
        # Progress log
        progress_log = "\n".join([f"â€¢ {msg}" for msg in progress_messages])
        
        # Create export file if requested
        export_file = None
        if export_format != "None":
            export_file = self.create_export(result['text'], export_format, trans_id)
        
        return (
            output_text,
            progress_log,
            self.analytics.create_fun_stats_card(),
            self.analytics.create_language_donut(),
            self.analytics.create_speed_chart(),
            export_file
        )
    
    def create_export(self, text: str, format: str, trans_id: str) -> str:
        """Create export file"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"darshjai_transcription_{timestamp}"
        
        if format == "Text (.txt)":
            filepath = f"{filename}.txt"
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"Darshj.AI Transcription\n")
                f.write(f"ID: {trans_id}\n")
                f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("="*50 + "\n\n")
                f.write(text)
            return filepath
        
        elif format == "JSON (.json)":
            filepath = f"{filename}.json"
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump({
                    'transcription_id': trans_id,
                    'timestamp': datetime.now().isoformat(),
                    'text': text,
                    'word_count': len(text.split()),
                    'character_count': len(text),
                    'powered_by': 'Darshj.AI'
                }, f, indent=2)
            return filepath
        
        return None
    
    def search_memory(self, query: str) -> str:
        """Search through transcription memory"""
        if not query:
            return "ğŸ” Enter a search query to find past transcriptions"
        
        results = self.memory.search(query)
        if not results:
            return f"âŒ No results found for '{query}'"
        
        output = f"ğŸ” **Found {len(results)} result(s) for '{query}':**\n\n"
        for i, result in enumerate(results, 1):
            output += f"**Result {i}** (ID: {result['id']})\n"
            output += f"Date: {result['timestamp']}\n"
            output += f"Preview: {result['text'][:200]}...\n\n"
        
        return output
    
    def create_interface(self):
        """Create the Gradio interface with Darshj.AI branding"""
        
        # Custom CSS for branding
        custom_css = """
        .gradio-container {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;
        }
        .gr-button-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
            border: none !important;
        }
        .gr-button-primary:hover {
            transform: translateY(-2px) !important;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4) !important;
        }
        """
        
        with gr.Blocks(
            theme=gr.themes.Soft(
                primary_hue="purple",
                secondary_hue="indigo"
            ),
            css=custom_css,
            title="ğŸ¯ Darshj.AI - Transcription Magic"
        ) as interface:
            
            # Header with animation
            gr.HTML("""
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        padding: 40px; border-radius: 20px; text-align: center; color: white;
                        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);">
                <h1 style="margin: 0; font-size: 3.5em; font-weight: bold;">
                    ğŸ¯ Darshj.AI
                </h1>
                <p style="font-size: 1.3em; margin-top: 10px; opacity: 0.95;">
                    âœ¨ Transcribe Anything, Anywhere, Anytime! âœ¨
                </p>
                <div style="margin-top: 20px;">
                    <span style="background: rgba(255,255,255,0.2); padding: 5px 15px; 
                                 border-radius: 20px; margin: 0 5px;">ğŸ™ï¸ Audio</span>
                    <span style="background: rgba(255,255,255,0.2); padding: 5px 15px; 
                                 border-radius: 20px; margin: 0 5px;">ğŸ¬ Video</span>
                    <span style="background: rgba(255,255,255,0.2); padding: 5px 15px; 
                                 border-radius: 20px; margin: 0 5px;">ğŸ¤– AI-Powered</span>
                </div>
            </div>
            """)
            
            # Main content tabs
            with gr.Tabs():
                # Transcription Tab
                with gr.TabItem("ğŸ™ï¸ Transcribe", id=1):
                    with gr.Row():
                        with gr.Column(scale=1):
                            gr.Markdown("### ğŸ“¤ Upload Your File")
                            
                            file_input = gr.File(
                                label="Drag & Drop or Click to Upload",
                                file_types=[".mp3", ".wav", ".mp4", ".avi", ".mov", 
                                          ".flac", ".m4a", ".webm", ".ogg"],
                                elem_id="file_upload"
                            )
                            
                            language = gr.Dropdown(
                                choices=["Auto-detect", "en", "es", "fr", "de", "it", 
                                        "pt", "ru", "ja", "ko", "zh"],
                                value="Auto-detect",
                                label="ğŸŒ Language",
                                interactive=True
                            )
                            
                            task = gr.Radio(
                                choices=["transcribe", "translate"],
                                value="transcribe",
                                label="ğŸ“ Task",
                                info="Transcribe keeps original language, Translate converts to English"
                            )
                            
                            export_format = gr.Radio(
                                choices=["None", "Text (.txt)", "JSON (.json)"],
                                value="None",
                                label="ğŸ’¾ Export Format"
                            )
                            
                            process_btn = gr.Button(
                                "ğŸš€ Start Transcription Magic!",
                                variant="primary",
                                size="lg"
                            )
                        
                        with gr.Column(scale=2):
                            gr.Markdown("### ğŸ“ Results")
                            
                            output_text = gr.Textbox(
                                label="Transcription Output",
                                lines=15,
                                max_lines=25,
                                placeholder="Your transcription will appear here... âœ¨"
                            )
                            
                            progress_log = gr.Textbox(
                                label="ğŸ¬ Progress Log",
                                lines=3,
                                placeholder="Processing steps will appear here..."
                            )
                            
                            export_file = gr.File(
                                label="ğŸ“¥ Download Export",
                                visible=True
                            )
                
                # Analytics Tab
                with gr.TabItem("ğŸ“Š Analytics", id=2):
                    gr.Markdown("### ğŸ“ˆ Your Transcription Analytics")
                    
                    stats_display = gr.HTML(
                        value=self.analytics.create_fun_stats_card()
                    )
                    
                    with gr.Row():
                        lang_chart = gr.Plot(
                            value=self.analytics.create_language_donut()
                        )
                        speed_chart = gr.Plot(
                            value=self.analytics.create_speed_chart()
                        )
                    
                    activity_chart = gr.Plot(
                        value=self.analytics.create_daily_heatmap()
                    )
                    
                    refresh_btn = gr.Button("ğŸ”„ Refresh Analytics", size="sm")
                
                # Memory Tab
                with gr.TabItem("ğŸ§  Memory", id=3):
                    gr.Markdown("### ğŸ” Search Your Transcription History")
                    
                    search_input = gr.Textbox(
                        label="Search Query",
                        placeholder="Enter keywords to search past transcriptions..."
                    )
                    
                    search_btn = gr.Button("ğŸ” Search", variant="primary")
                    
                    search_results = gr.Textbox(
                        label="Search Results",
                        lines=10,
                        placeholder="Results will appear here..."
                    )
                    
                    gr.Markdown("### ğŸ“œ Recent Transcriptions")
                    recent_btn = gr.Button("ğŸ“œ Show Recent", size="sm")
                    recent_display = gr.JSON(label="Recent Transcriptions")
                
                # About Tab
                with gr.TabItem("â„¹ï¸ About", id=4):
                    gr.Markdown("""
                    ## ğŸ¯ About Darshj.AI
                    
                    ### ğŸš€ Features
                    - **ğŸ™ï¸ Universal Support**: Transcribe any audio/video format
                    - **ğŸ¤– AI-Powered**: Using OpenAI's Whisper technology
                    - **âš¡ Lightning Fast**: GPU-accelerated processing
                    - **ğŸŒ Multilingual**: Support for 10+ languages
                    - **ğŸ“Š Analytics**: Track your usage and performance
                    - **ğŸ§  Memory**: Search through past transcriptions
                    - **ğŸ’¾ Export**: Save in multiple formats
                    
                    ### ğŸ† Achievement Levels
                    - ğŸŒŸ **Beginner** (0-4 files)
                    - â­ **Rising Star** (5-9 files)
                    - ğŸ¥‰ **Enthusiast** (10-19 files)
                    - ğŸ¥ˆ **Pro** (20-49 files)
                    - ğŸ¥‡ **Expert** (50-99 files)
                    - ğŸ† **Master** (100+ files)
                    
                    ### ğŸ‘¨â€ğŸ’» Created by Darshj.AI
                    Made with â¤ï¸ and lots of â˜•
                    
                    ### ğŸ“ Support
                    For questions or feedback, reach out to the Darshj.AI team!
                    
                    ---
                    
                    <div style="text-align: center; margin-top: 30px;">
                        <h3>ğŸ‰ Thank you for using Darshj.AI! ğŸ‰</h3>
                    </div>
                    """)
            
            # Footer
            gr.HTML("""
            <div style="text-align: center; padding: 20px; opacity: 0.7;">
                <p>Powered by ğŸ¯ Darshj.AI | Built with Whisper & Gradio | 
                <span style="color: #667eea;">v1.0.0</span></p>
            </div>
            """)
            
            # Event handlers
            process_btn.click(
                fn=self.process_file_with_magic,
                inputs=[file_input, language, task, export_format],
                outputs=[output_text, progress_log, stats_display, 
                        lang_chart, speed_chart, export_file]
            )
            
            refresh_btn.click(
                fn=lambda: [
                    self.analytics.create_fun_stats_card(),
                    self.analytics.create_language_donut(),
                    self.analytics.create_speed_chart(),
                    self.analytics.create_daily_heatmap()
                ],
                outputs=[stats_display, lang_chart, speed_chart, activity_chart]
            )
            
            search_btn.click(
                fn=self.search_memory,
                inputs=[search_input],
                outputs=[search_results]
            )
            
            recent_btn.click(
                fn=lambda: self.memory.get_recent(5),
                outputs=[recent_display]
            )
        
        return interface

# %% [markdown]
# ## ğŸš€ Step 7: Launch the Magic!

# %%
# Initialize the dashboard
print("\n" + "="*60)
print("ğŸ¯ DARSHJ.AI TRANSCRIPTION DASHBOARD")
print("="*60)

dashboard = DarshjTranscriptionDashboard()
interface = dashboard.create_interface()

print("\nğŸŒŸ Launching Darshj.AI Dashboard...")
print("ğŸ“ Local URL will appear below")
print("ğŸŒ Public URL will be generated\n")

# Launch with custom settings
interface.launch(
    share=True,  # Create public shareable link
    server_name="0.0.0.0",
    server_port=7860,
    favicon_path=None,
    show_error=True,
    quiet=False
)

# %% [markdown]
# ## ğŸ‰ Congratulations!
# 
# Your **Darshj.AI Transcription Dashboard** is now running! 
# 
# ### ğŸ“ Quick Tips:
# 1. Upload any audio/video file to get started
# 2. Check the Analytics tab to see your progress
# 3. Use Memory search to find past transcriptions
# 4. Export your transcriptions in different formats
# 
# ### ğŸš€ Share this tool with friends!
# 
# ---
# 
# <div align="center">
#     <h2>Made with â¤ï¸ by Darshj.AI</h2>
# </div>
